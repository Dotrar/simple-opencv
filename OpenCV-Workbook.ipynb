{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd02550ab4d7614798a918516aa84ae238d86d2cbdb42176732070dc023bdc12baf",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "738d3aba0355ef2d4c4d5621637f2966c8cccd2d7de3ec1cc43188ba2950123a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# OpenCV Simple example\n",
    "going through some simple tests to make sure the camera works as expected\n",
    "This is using the `opencv` library, install via pip with `opencv-python`\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Does the camera work correctly? \n",
    "\n",
    "Basically look for \"opencv camera tutorial\" on your platform and start from there.\n",
    "'''\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "interface=0\n",
    "camera = cv2.VideoCapture(interface)\n",
    "\n",
    "while True:\n",
    "    _, img = camera.read()\n",
    "    if img is None:\n",
    "        print(f\"Unable to open camera {interface=}\")\n",
    "        break\n",
    "    cv2.imshow(\"simple camera test\", img)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 0 - breaking up the image\n",
    "\n",
    "while True: \n",
    "    _, img = camera.read()\n",
    "    if img is None:\n",
    "        print(f\"Unable to open camera {interface=}\")\n",
    "        break\n",
    "    # split image\n",
    "    img_size = np.shape(img)[:-1]\n",
    "    \n",
    "    # Originally, this was showing channels in the channel colour\n",
    "    # but it doesn't look great and doesn't explain the colour differences\n",
    "    # Easily.\n",
    "    # filler = (np.zeros((img_size)),np.zeros((img_size)))\n",
    "    # b_img = cv2.convertScaleAbs(np.dstack((img[:,:,0],*filler)))\n",
    "    # g_img = cv2.convertScaleAbs(np.dstack((filler[0],img[:,:,1],filler[0])))\n",
    "    # r_img = cv2.convertScaleAbs(np.dstack((*filler,img[:,:,2])))\n",
    "       \n",
    "    # First, make an image, \"convert\" it to 3-channel so we have access to RGB values\n",
    "    b_img = cv2.cvtColor(img[:,:,0],cv2.COLOR_GRAY2BGR)\n",
    "    # Then superimpose text, in that colour value.\n",
    "    b_img = cv2.putText(b_img,'Blue', (10,40),cv2.FONT_HERSHEY_COMPLEX,2,(255,0,0),2)\n",
    "    g_img = cv2.cvtColor(img[:,:,1],cv2.COLOR_GRAY2BGR)\n",
    "    g_img = cv2.putText(g_img,'Green', (10,40),cv2.FONT_HERSHEY_COMPLEX,2,(0,255,0),2)\n",
    "    r_img = cv2.cvtColor(img[:,:,2],cv2.COLOR_GRAY2BGR)\n",
    "    r_img = cv2.putText(r_img,'Red', (10,40),cv2.FONT_HERSHEY_COMPLEX,2,(0,0,255),2)\n",
    "    img = cv2.putText(img, 'Truth', (10,40), cv2.FONT_HERSHEY_COMPLEX,2,(0,0,0),2)\n",
    "\n",
    "    \n",
    "    # stack next to each other ( vstack / hstack )\n",
    "    hza = np.hstack((b_img,g_img))\n",
    "    hzb = np.hstack((r_img, img))\n",
    "    hz = np.vstack((hza,hzb))\n",
    "    cv2.imshow('3 Seperate channels', hz)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "del img, b_img, g_img, r_img, hz,hza,hzb"
   ]
  },
  {
   "source": [
    "# Part 1 - Thresholding\n",
    "\n",
    "```python\n",
    "for pixel in image:\n",
    "    if pixel.value > thresh:\n",
    "        pixel = BLACK\n",
    "    else:\n",
    "        pixel = WHITE\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BLUE_THRESHOLD_VALUE = 100\n",
    "RED_THRESHOLD_VALUE = 150 \n",
    "SIMPLE = True\n",
    "THREE_PANEL = False\n",
    "MASK_EXAMPLE = False\n",
    "while True: \n",
    "    _, img = camera.read()\n",
    "    if img is None:\n",
    "        print(f\"Unable to open camera {interface=}\")\n",
    "        break\n",
    "       \n",
    "    b_img = img[:,:,0]\n",
    "\n",
    "    # this is a single channel image\n",
    "    if SIMPLE:\n",
    "        _,b_imgt = cv2.threshold(b_img, BLUE_THRESHOLD_VALUE,255, cv2.THRESH_BINARY)\n",
    "    else: \n",
    "        b_imgt = cv2.adaptiveThreshold(b_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 5,2)\n",
    "    #convert back to 3channel\n",
    "    b_img = cv2.cvtColor(b_imgt, cv2.COLOR_GRAY2BGR)\n",
    "    # Then superimpose text, in that colour value.\n",
    "    b_img = cv2.putText(b_img,'BLUE THRESH', (10,40),cv2.FONT_HERSHEY_COMPLEX,2,(255,100,100),2)\n",
    "\n",
    "    r_img = img[:,:,2]\n",
    "    if SIMPLE:\n",
    "        _,r_imgt = cv2.threshold(r_img, RED_THRESHOLD_VALUE,255, cv2.THRESH_BINARY)\n",
    "    else:\n",
    "        r_imgt = cv2.adaptiveThreshold(r_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 5,2)\n",
    "\n",
    "    r_img = cv2.cvtColor(r_imgt, cv2.COLOR_GRAY2BGR)\n",
    "    # Then superimpose text, in that colour value.\n",
    "    r_img = cv2.putText(r_img,'RED THRESH', (10,40),cv2.FONT_HERSHEY_COMPLEX,2,(100,100,255),2)\n",
    "\n",
    "    br_xor = np.bitwise_xor(b_imgt, r_imgt)\n",
    "    if MASK_EXAMPLE:\n",
    "        hz = cv2.putText(cv2.bitwise_and(img,img, mask = np.bitwise_xor(b_imgt,r_imgt)),'MASKED', (10,40), cv2.FONT_HERSHEY_COMPLEX,2,(255,255,255),2)\n",
    "        hzb = 0\n",
    "\n",
    "    elif THREE_PANEL:\n",
    "        # stack next to each other ( vstack / hstack )\n",
    "        hz = np.hstack((b_img,img,r_img))\n",
    "        hzb = 0\n",
    "    else:\n",
    "        hz = np.hstack((b_img, r_img))\n",
    "        hzb = np.hstack((img, cv2.putText(cv2.cvtColor(br_xor,cv2.COLOR_GRAY2BGR),\n",
    "        'XOR', (10,40),cv2.FONT_HERSHEY_COMPLEX,2,(255,100,255),2)))\n",
    "\n",
    "        hz = np.vstack((hz, hzb, \n",
    "        np.hstack((\n",
    "            cv2.putText(\n",
    "                cv2.cvtColor(\n",
    "                    np.bitwise_and(b_imgt,br_xor),\n",
    "                    cv2.COLOR_GRAY2BGR\n",
    "                    ),'BLUE+XOR', (10,40),cv2.FONT_HERSHEY_COMPLEX,2,(255,200,200),2)\n",
    "            ,\n",
    "            cv2.putText(\n",
    "                cv2.cvtColor(\n",
    "                    np.bitwise_and(r_imgt, br_xor),\n",
    "                    cv2.COLOR_GRAY2BGR\n",
    "                    ),'RED+XOR', (10,40),cv2.FONT_HERSHEY_COMPLEX,2,(200,200,255),2)\n",
    "        ))\n",
    "        ))\n",
    "\n",
    "    cv2.imshow('simple thresholding', hz)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "# del img, b_img, hzb, r_imgt, b_imgt, r_img, hz"
   ]
  },
  {
   "source": [
    "# Part 2 Eroding and Dilating (Super simple, quick part)\n",
    "This is just a very simple way to understand the erosion and dilation functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "KERNEL_SIZE = 3\n",
    "while True: \n",
    "    _, img = camera.read()\n",
    "    if img is None:\n",
    "        print(f\"Unable to open camera {interface=}\")\n",
    "        break\n",
    "       \n",
    "    b_img = img[:,:,0]\n",
    "\n",
    "    _,b_imgt = cv2.threshold(b_img, BLUE_THRESHOLD_VALUE,255, cv2.THRESH_BINARY)\n",
    "    #convert back to 3channel\n",
    "    b_img = cv2.cvtColor(b_imgt, cv2.COLOR_GRAY2BGR)\n",
    "    # Then superimpose text, in that colour value.\n",
    "    b_img = cv2.putText(b_img,'BLUE THRESH', (10,40),cv2.FONT_HERSHEY_COMPLEX,2,(255,100,100),2)\n",
    "\n",
    "    r_img = img[:,:,2]\n",
    "   \n",
    "    _,r_imgt = cv2.threshold(r_img, RED_THRESHOLD_VALUE,255, cv2.THRESH_BINARY)\n",
    "   \n",
    "    r_img = cv2.cvtColor(r_imgt, cv2.COLOR_GRAY2BGR)\n",
    "    # Then superimpose text, in that colour value.\n",
    "    r_img = cv2.putText(r_img,'RED THRESH', (10,40),cv2.FONT_HERSHEY_COMPLEX,2,(100,100,255),2)\n",
    "\n",
    "    mask = np.bitwise_xor(b_imgt,r_imgt)\n",
    "    kernel = np.ones((KERNEL_SIZE, KERNEL_SIZE))\n",
    "    eroded = cv2.erode(mask, kernel)\n",
    "    dilate = cv2.dilate(mask,kernel)\n",
    "    both = cv2.dilate(cv2.erode(mask,kernel),kernel)\n",
    "\n",
    "    applied = cv2.bitwise_and(img,img, mask=both)\n",
    "\n",
    "    hz = np.vstack((\n",
    "        np.hstack((\n",
    "            cv2.putText(cv2.cvtColor(mask,cv2.COLOR_GRAY2BGR), \"Original\",(10,40),cv2.FONT_HERSHEY_COMPLEX,2,(255,100,100),2),\n",
    "            cv2.putText(cv2.cvtColor(eroded,cv2.COLOR_GRAY2BGR), \"Eroded\",(10,40),cv2.FONT_HERSHEY_COMPLEX,2,(255,100,100),2)\n",
    "            )),\n",
    "        np.hstack((\n",
    "            cv2.putText(cv2.cvtColor(dilate,cv2.COLOR_GRAY2BGR), \"Dilate\",(10,40),cv2.FONT_HERSHEY_COMPLEX,2,(255,100,100),2),\n",
    "            cv2.putText(cv2.cvtColor(both,cv2.COLOR_GRAY2BGR), \"Erode then Dilate\",(10,40),cv2.FONT_HERSHEY_COMPLEX,2,(255,100,100),2)\n",
    "            ))\n",
    "    ))\n",
    "\n",
    "    # draw simple lines to break up the image\n",
    "    hz = cv2.line(hz, (640,0), (640,960), (100,100,255), 3)\n",
    "    hz = cv2.line(hz, (0,480), (1280,480), (100,100,255),3)\n",
    "\n",
    "    cv2.imshow('eroding', hz)\n",
    "    cv2.imshow('mask applied', applied)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "del hz, mask, kernel, eroded, dilate, both, applied "
   ]
  },
  {
   "source": [
    "# Anyway, on with BlobDector\n",
    "Simple blob detector is an alorithim that just brings together \"blobs\" of pixel data, working off black and white images.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "created blob detector\n"
     ]
    }
   ],
   "source": [
    "BLUE_THRESHOLD_VALUE = 100\n",
    "RED_THRESHOLD_VALUE = 150\n",
    "GREEN_THRESHOLD_VALUE = 100\n",
    "\n",
    "KERNEL_SIZE = 3\n",
    "kernel = np.ones((KERNEL_SIZE, KERNEL_SIZE))\n",
    "# Setup SimpleBlobDetector parameters.\n",
    "params = cv2.SimpleBlobDetector_Params()\n",
    "\n",
    "# Change thresholds\n",
    "params.minThreshold = 10\n",
    "params.maxThreshold = 200\n",
    "\n",
    "\n",
    "# Filter by Area.\n",
    "params.filterByArea = True\n",
    "params.minArea = 1500\n",
    "\n",
    "# Filter by Circularity\n",
    "params.filterByCircularity = True\n",
    "params.minCircularity = 0.1\n",
    "\n",
    "# Filter by Convexity\n",
    "params.filterByConvexity = True\n",
    "params.minConvexity = 0.87\n",
    "\n",
    "# Filter by Inertia\n",
    "params.filterByInertia = True\n",
    "params.minInertiaRatio = 0.01\n",
    "\n",
    "\n",
    "detector = cv2.SimpleBlobDetector_create(params)\n",
    "print(\"created blob detector\")\n",
    "while True: \n",
    "    _, img = camera.read()\n",
    "    if img is None:\n",
    "        print(f\"Unable to open camera {interface=}\")\n",
    "        break\n",
    "\n",
    "    b_img = img[:,:,0]\n",
    "    img_size = np.shape(b_img)\n",
    "    _,b_imgt = cv2.threshold(b_img, BLUE_THRESHOLD_VALUE,255, cv2.THRESH_BINARY)\n",
    "    b_imgt = cv2.dilate(cv2.erode(b_imgt,kernel),kernel)\n",
    "    #b_imgt = np.bitwise_not(b_imgt)\n",
    "    # r_img = img[:,:,2]\n",
    "    # _,r_imgt = cv2.threshold(r_img, RED_THRESHOLD_VALUE,255, cv2.THRESH_BINARY)\n",
    "    # g_img = img[:,:,2]\n",
    "    # _,g_imgt = cv2.threshold(r_img, RED_THRESHOLD_VALUE,255, cv2.THRESH_BINARY)\n",
    "    keypoints = detector.detect(b_imgt)\n",
    "    key_image = cv2.drawKeypoints(np.zeros(img_size,dtype=np.uint8),keypoints,np.array([]),(0,165,255),cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    display = cv2.drawKeypoints(img,keypoints,np.array([]),(0,165,255),cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    # y_imgt = np.bitwise_and(g_imgt, r_imgt)\n",
    "    # m_imgt = np.bitwise_and(b_imgt, g_imgt)\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(b_imgt, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)    \n",
    "\n",
    "    for i in range(len(contours)):\n",
    "        cv2.drawContours(display, contours, i, (100,255,100),2, cv2.LINE_AA, hierarchy,0)\n",
    "\n",
    "    hz = np.hstack((img,cv2.cvtColor(b_imgt, cv2.COLOR_GRAY2BGR)))\n",
    "    hz = np.vstack((hz,\n",
    "    np.hstack((key_image,display))\n",
    "    ))\n",
    "\n",
    "    cv2.imshow('New Im', hz)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "# del img, b_img, hzb, r_imgt, b_imgt, r_img, hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}